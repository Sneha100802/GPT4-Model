# -*- coding: utf-8 -*-
"""LearnAnyBhasha_Chatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1myQ-eO1vjmaA9OGeTcl-VIqNUbk43J9i
"""

import streamlit as st
from gpt4all import GPT4All

MODEL_PATH = r"C:\Users\jhasn\Downloads"
MODEL_NAME = "gpt4all-falcon-Q2_K.gguf"

@st.cache_resource
def load_model():
    return GPT4All(MODEL_NAME, model_path=MODEL_PATH, allow_download=False, n_threads=4, n_ctx=512)

llm = load_model()
st.write("âœ… Model loaded successfully!")

st.title("ðŸ’¬ GPT4All Chatbot")

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display chat history
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# User input
user_input = st.chat_input("Type your message...")
if user_input:
    # Display user message
    st.session_state.messages.append({"role": "user", "content": user_input})
    st.chat_message("user").write(user_input)

    # Get AI response
    response = llm.generate(user_input)
    st.session_state.messages.append({"role": "assistant", "content": response})
    st.chat_message("assistant").write(response)

